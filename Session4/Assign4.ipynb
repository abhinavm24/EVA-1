{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "####  **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "outputId": "1cd2b309-233f-427f-9401-31c0f932ffc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as k\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets\n",
        "Plotting a sample image from the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "b439e658-77b6-4975-c5a0-ef94e2b19c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2433b45160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsvS3ZKYzCDl",
        "colab_type": "text"
      },
      "source": [
        "Normalise the pixel values to get values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2flpl1ptOgT",
        "colab_type": "text"
      },
      "source": [
        "One hot encoding the labels from training and test set. Each 1d label is converted to 10d sparse matrix. Eg, digit 2 becomes [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZLSWxZgKgyA",
        "colab_type": "text"
      },
      "source": [
        "#### Original model\n",
        "68K parameters giving accuracy of 99.54% after 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9M-xW84KLPy",
        "colab_type": "code",
        "outputId": "7c07927f-fa18-489a-b179-f2ef101e8389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(10, 1, activation='relu'))\n",
        "model.add(Conv2D(10, 26))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 10)        330       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 1, 1, 10)          67610     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 68,260\n",
            "Trainable params: 68,260\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqatcCWKnqe",
        "colab_type": "code",
        "outputId": "6ae79672-e8c9-42a8-cbc8-f53962e11c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 16:09:47.538334 140454548146048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0805 16:09:47.613204 140454548146048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 18s 306us/step - loss: 0.2103 - acc: 0.9403\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.0791 - acc: 0.9770\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0577 - acc: 0.9826\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 223us/step - loss: 0.0455 - acc: 0.9859\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.0378 - acc: 0.9883\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0311 - acc: 0.9899\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.0259 - acc: 0.9916\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0206 - acc: 0.9932\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0179 - acc: 0.9938\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0140 - acc: 0.9954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbdd443e9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcvK6SctJunN",
        "colab_type": "text"
      },
      "source": [
        "## First code iteration - Reduced parameters from 68000 to 13,746 which is less than 15,000 parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_first_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))  # output size - 26x26, RF-3\n",
        "  model.add(Conv2D(16, 3, 3, activation='relu'))  # output size - 24x24, RF-5\n",
        "  model.add(Conv2D(16, 3, 3, activation='relu'))  # output size - 22x22, RF-7\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))    # output size - 11x11, RF-14\n",
        "  model.add(Conv2D(10, 1, activation='relu'))  # output size - 11x11, RF-14\n",
        "\n",
        "  model.add(Conv2D(16, 3, 3, activation='relu')) # output size - 9x9, RF-16\n",
        "  model.add(Conv2D(16, 3, 3, activation='relu'))  # output size - 7x7, RF-18\n",
        "  model.add(Conv2D(16, 3, 3, activation='relu'))  # output size is 5x5, RF-20\n",
        "    \n",
        "  model.add(Conv2D(10, 1, 1, activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(10, 5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlU_ByhSV7l0",
        "colab_type": "text"
      },
      "source": [
        "#### Changes in the new model:\n",
        "\n",
        "*   Added transition block(max pooling+pointwise conv) after 3 layers of convolution with (3x3) kernel.\n",
        "*   Increased number of conv layers to 9 from 3. The last convolution layer which is flattened has 5x5\n",
        "instead of 26x26.\n",
        "* Changed number of kernels in each convolution layer to 16 to limit the number of parameters.\n",
        "Another approach could have been lesser convolution layers and increasing number of kernels from 16 to 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "3fc59ea4-a211-4600-9199-e8716cb6c60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "model=build_first_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 5, 5, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,746\n",
            "Trainable params: 13,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynoLE8dltqTF",
        "colab_type": "text"
      },
      "source": [
        "#### Trained the new model for 20 epochs.  Best validation accuracy was 99.19 at epoch 13, when training acc was 99.28%. After this model started overfitting since training acc increased to 99.5% at epoch 18, but validation became 98.95%. \n",
        "We continue with this network for the next code iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn1ljkVuI733",
        "colab_type": "code",
        "outputId": "75e60757-ddf9-4ef2-ec50-ade077acea8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.2602 - acc: 0.9179 - val_loss: 0.0859 - val_acc: 0.9740\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0880 - acc: 0.9731 - val_loss: 0.0664 - val_acc: 0.9801\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0640 - acc: 0.9807 - val_loss: 0.0508 - val_acc: 0.9850\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0523 - acc: 0.9840 - val_loss: 0.0437 - val_acc: 0.9865\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0435 - acc: 0.9867 - val_loss: 0.0470 - val_acc: 0.9850\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0391 - acc: 0.9880 - val_loss: 0.0493 - val_acc: 0.9838\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0350 - acc: 0.9890 - val_loss: 0.0301 - val_acc: 0.9902\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0324 - acc: 0.9895 - val_loss: 0.0354 - val_acc: 0.9893\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0350 - val_acc: 0.9888\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0331 - val_acc: 0.9894\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.0343 - val_acc: 0.9894\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0344 - val_acc: 0.9904\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0219 - acc: 0.9928 - val_loss: 0.0310 - val_acc: 0.9919\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.0367 - val_acc: 0.9904\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0181 - acc: 0.9940 - val_loss: 0.0391 - val_acc: 0.9899\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0398 - val_acc: 0.9901\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.0420 - val_acc: 0.9890\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0394 - val_acc: 0.9895\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0400 - val_acc: 0.9896\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0152 - acc: 0.9945 - val_loss: 0.0406 - val_acc: 0.9887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5a027f828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3jZgs1wYyTy",
        "colab_type": "text"
      },
      "source": [
        "## Second Code iteration - Need to reduce overfitting which is done by adding dropout.\n",
        "Small dropout of 10% is added after every Convolution (3,3) layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_second_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))    # after this size is 11x11, RF-14\n",
        "  model.add(Conv2D(10, 1, activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))  # after this size is 5x5, RF-20\n",
        "  model.add(Dropout(0.1))\n",
        "    \n",
        "  model.add(Conv2D(10, 1, activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(10, 5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "1dbf2e13-d563-4a6b-99aa-59297d3d8bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_second_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0811 04:10:32.279354 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0811 04:10:32.316823 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0811 04:10:32.323195 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0811 04:10:32.351069 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0811 04:10:32.359732 139705203124096 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0811 04:10:32.435288 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0811 04:10:32.678841 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0811 04:10:32.700098 139705203124096 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,746\n",
            "Trainable params: 13,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "outputId": "7e1cc2f2-c5a8-4674-cd60-a1998df84947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "dir=\"/content/gdrive/My Drive/Colab Notebooks/EVA/Weights/\"\n",
        "file = dir + \"Assign4.2.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apOlWGHGz9zA",
        "colab_type": "text"
      },
      "source": [
        "#### Trained the new model for 20 epochs.  Best validation accuracy was 99.3 at epoch 17, when training acc was 99.03%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "a5e6ba55-a0cc-476c-e5d9-673524c23476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 30s 498us/step - loss: 0.2849 - acc: 0.9087 - val_loss: 0.0708 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.97780, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.01-0.9778.hdf5\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0929 - acc: 0.9715 - val_loss: 0.0547 - val_acc: 0.9830\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.97780 to 0.98300, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.02-0.9830.hdf5\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0719 - acc: 0.9778 - val_loss: 0.0491 - val_acc: 0.9838\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98300 to 0.98380, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.03-0.9838.hdf5\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0605 - acc: 0.9816 - val_loss: 0.0333 - val_acc: 0.9890\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98380 to 0.98900, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.04-0.9890.hdf5\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 28s 468us/step - loss: 0.0547 - acc: 0.9834 - val_loss: 0.0482 - val_acc: 0.9840\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.98900\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 28s 466us/step - loss: 0.0500 - acc: 0.9849 - val_loss: 0.0302 - val_acc: 0.9901\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.98900 to 0.99010, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.06-0.9901.hdf5\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 28s 466us/step - loss: 0.0462 - acc: 0.9861 - val_loss: 0.0316 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99010\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 28s 466us/step - loss: 0.0446 - acc: 0.9858 - val_loss: 0.0361 - val_acc: 0.9891\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99010\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 28s 468us/step - loss: 0.0416 - acc: 0.9872 - val_loss: 0.0296 - val_acc: 0.9897\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99010\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.0266 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99010\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0379 - acc: 0.9883 - val_loss: 0.0297 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99010\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.0376 - acc: 0.9880 - val_loss: 0.0287 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.99010 to 0.99050, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.12-0.9905.hdf5\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 28s 462us/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.0228 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99050 to 0.99260, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.13-0.9926.hdf5\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0340 - acc: 0.9889 - val_loss: 0.0269 - val_acc: 0.9898\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99260\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99260\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.0334 - acc: 0.9893 - val_loss: 0.0288 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99260\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 28s 462us/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0243 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.99260 to 0.99300, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.2.17-0.9930.hdf5\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0292 - acc: 0.9905 - val_loss: 0.0261 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99300\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.0232 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99300\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 28s 474us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0251 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c43003748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM36DTwK0xit",
        "colab_type": "code",
        "outputId": "3a7c0b30-7160-4ba7-f5a5-4ca0c932f25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(dir + \"Assign4.2.17-0.9930.hdf5\")\n",
        "print(\"Loaded model from disk \")\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk \n",
            "[0.024330410757218486, 0.993]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpGg43Ey2mLH",
        "colab_type": "text"
      },
      "source": [
        "## Third Code iteration - Added Batch Normalisation after every Conv layer\n",
        "\n",
        "6 layers of batch normalisation added a few more trainable parameters to make it **14130**.\n",
        "And number of non trainable params 192."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932WQTzj2m2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_third_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))    # after this size is 11x11, RF-14\n",
        "  model.add(Conv2D(10, 1, activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(16, (3, 3), activation='relu'))  # after this size is 5x5, RF-20\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "    \n",
        "  model.add(Conv2D(10, 1, activation='relu'))\n",
        "\n",
        "  model.add(Conv2D(10, 5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6SQbtZ7813R",
        "colab_type": "text"
      },
      "source": [
        "#### Trained the new model for 30 epochs for batch_sizes 32 and 64. Result:\n",
        "* Batch_size 32 : Best validation accuracy was **99.4 at epoch 19**, when training acc was 99.25%. \n",
        "* Batch_size 64 : Best validation accuracy was **99.36 at epoch 21**, when training acc was 99.24%.\n",
        "\n",
        "Batch_size 32, was marginally better, though it may not be consistent for every run. Also it takes more time ~22s. (64 takes 11s). We continue with this batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNcsEv4292O",
        "colab_type": "code",
        "outputId": "22613392-05bd-4f02-dc81-ee67697e7846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_third_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "file = dir + \"Assign4.3.{epoch:02d}-{val_acc:.4f}.hdf5\" \n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_38 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 5, 5, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,130\n",
            "Trainable params: 13,938\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.2275 - acc: 0.9284 - val_loss: 0.0573 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98110, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.01-0.9811.hdf5\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0449 - val_acc: 0.9866\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98110 to 0.98660, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.02-0.9866.hdf5\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0556 - acc: 0.9830 - val_loss: 0.0327 - val_acc: 0.9889\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98660 to 0.98890, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.03-0.9889.hdf5\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0479 - acc: 0.9849 - val_loss: 0.0313 - val_acc: 0.9898\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98890 to 0.98980, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.04-0.9898.hdf5\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.0426 - acc: 0.9864 - val_loss: 0.0292 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98980 to 0.99090, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.05-0.9909.hdf5\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0383 - acc: 0.9881 - val_loss: 0.0302 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99090\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0370 - acc: 0.9879 - val_loss: 0.0322 - val_acc: 0.9898\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99090\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0290 - val_acc: 0.9907\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99090\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.0338 - acc: 0.9892 - val_loss: 0.0272 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99090\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 22s 372us/step - loss: 0.0307 - acc: 0.9899 - val_loss: 0.0259 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.99090 to 0.99150, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.10-0.9915.hdf5\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0301 - acc: 0.9906 - val_loss: 0.0255 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99150 to 0.99190, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.11-0.9919.hdf5\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0298 - acc: 0.9907 - val_loss: 0.0235 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.99190 to 0.99220, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.12-0.9922.hdf5\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 22s 374us/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0258 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99220\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0255 - acc: 0.9921 - val_loss: 0.0263 - val_acc: 0.9906\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99220\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0215 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.99220 to 0.99240, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.15-0.9924.hdf5\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 22s 372us/step - loss: 0.0258 - acc: 0.9925 - val_loss: 0.0233 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99240\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0267 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99240\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0234 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99240\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0220 - acc: 0.9925 - val_loss: 0.0183 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.99240 to 0.99400, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.19-0.9940.hdf5\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 22s 374us/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.0239 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99400\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0271 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99400\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 22s 375us/step - loss: 0.0212 - acc: 0.9934 - val_loss: 0.0261 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99400\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0242 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99400\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0208 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99400\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0194 - acc: 0.9936 - val_loss: 0.0216 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99400\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.0242 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99400\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0224 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99400\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.0186 - acc: 0.9939 - val_loss: 0.0213 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99400\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0226 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99400\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 22s 365us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0271 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0edd66b278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_1HonxYacsq",
        "colab_type": "text"
      },
      "source": [
        "## Best accuracy till now at iteration 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Tu2Wj6Ze8P",
        "colab_type": "code",
        "outputId": "a556f810-07dd-48ce-95c4-8d400211320e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(dir + \"Assign4.3.19-0.9940.hdf5\")\n",
        "print(\"Loaded model from disk \")\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk \n",
            "[0.018334998509348225, 0.994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVf8f5seQaAk",
        "colab_type": "text"
      },
      "source": [
        "## Same model with batch_size 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbyeFK_j_UB0",
        "colab_type": "code",
        "outputId": "876fd5e2-b914-4ace-8566-c6a0a7caba22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_third_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "file = dir + \"Assign4.3.{epoch:02d}-{val_acc:.4f}.hdf5\" \n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=64, epochs=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 5, 5, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,130\n",
            "Trainable params: 13,938\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.3154 - acc: 0.8994 - val_loss: 0.0658 - val_acc: 0.9790\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.97900, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.01-0.9790.hdf5\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0750 - acc: 0.9766 - val_loss: 0.0502 - val_acc: 0.9831\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.97900 to 0.98310, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.02-0.9831.hdf5\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0587 - acc: 0.9819 - val_loss: 0.0389 - val_acc: 0.9873\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98310 to 0.98730, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.03-0.9873.hdf5\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0490 - acc: 0.9842 - val_loss: 0.0387 - val_acc: 0.9879\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98730 to 0.98790, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.04-0.9879.hdf5\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0460 - acc: 0.9856 - val_loss: 0.0379 - val_acc: 0.9867\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.98790\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0407 - acc: 0.9870 - val_loss: 0.0294 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.98790 to 0.99120, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.06-0.9912.hdf5\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0385 - acc: 0.9877 - val_loss: 0.0344 - val_acc: 0.9898\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99120\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0374 - acc: 0.9884 - val_loss: 0.0376 - val_acc: 0.9881\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99120\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0330 - acc: 0.9891 - val_loss: 0.0306 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99120\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0310 - acc: 0.9899 - val_loss: 0.0292 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99120\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0309 - acc: 0.9903 - val_loss: 0.0236 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99120 to 0.99250, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.11-0.9925.hdf5\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0334 - val_acc: 0.9888\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99250\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0272 - acc: 0.9907 - val_loss: 0.0285 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99250\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0269 - acc: 0.9915 - val_loss: 0.0227 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99250\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0255 - acc: 0.9916 - val_loss: 0.0282 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99250\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0259 - acc: 0.9919 - val_loss: 0.0294 - val_acc: 0.9903\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99250\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0238 - acc: 0.9921 - val_loss: 0.0273 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99250\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0239 - acc: 0.9920 - val_loss: 0.0244 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99250\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0235 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.99250 to 0.99280, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.19-0.9928.hdf5\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0262 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99280\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0223 - acc: 0.9924 - val_loss: 0.0207 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.99280 to 0.99360, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.3.21-0.9936.hdf5\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0230 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99360\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.0304 - val_acc: 0.9913\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99360\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0282 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99360\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0236 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99360\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0240 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99360\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0263 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99360\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0237 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99360\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0228 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99360\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0237 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f406ef908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aNAim8SEaLtl"
      },
      "source": [
        "## Fourth Code iteration - Added LearningRateScheduler as callback to fit method, This is done for more fine grained gradient control.\n",
        "Used the model from previous iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "heKe5WEvihus",
        "colab": {}
      },
      "source": [
        "model=build_third_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n_Q9B_I0M_x",
        "colab_type": "text"
      },
      "source": [
        "#### Tried with 2 scheduler functions :\n",
        "\n",
        "1.   initial lr 0.003 till 0.00029\n",
        "2.   initial lr 0.001 till 0.00014"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZghjobacMF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "custom_lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7n1-A0o0XEy",
        "colab_type": "text"
      },
      "source": [
        "### 1. Best validation accuracy was 99.47 at epoch 24, when training acc was 99.54%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV1MikhYivrW",
        "colab_type": "code",
        "outputId": "fdd84f69-dade-4ca7-840c-dd370f987805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file = dir + \"Assign4.4.{epoch:02d}-{val_acc:.4f}.hdf5\" \n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test), callbacks=[checkpoint, custom_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 27s 454us/step - loss: 0.1681 - acc: 0.9477 - val_loss: 0.0530 - val_acc: 0.9829\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98290, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.01-0.9829.hdf5\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 24s 394us/step - loss: 0.0686 - acc: 0.9782 - val_loss: 0.0714 - val_acc: 0.9783\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.98290\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0535 - acc: 0.9833 - val_loss: 0.0489 - val_acc: 0.9830\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98290 to 0.98300, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.03-0.9830.hdf5\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0446 - acc: 0.9859 - val_loss: 0.0347 - val_acc: 0.9886\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98300 to 0.98860, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.04-0.9886.hdf5\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.0316 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98860 to 0.98930, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.05-0.9893.hdf5\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 0.0351 - acc: 0.9886 - val_loss: 0.0331 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.98930 to 0.99000, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.06-0.9900.hdf5\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0262 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.99000 to 0.99190, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.07-0.9919.hdf5\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0257 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.99190\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.0242 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99190 to 0.99200, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.09-0.9920.hdf5\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0244 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.99200 to 0.99210, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.10-0.9921.hdf5\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0235 - acc: 0.9926 - val_loss: 0.0212 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99210 to 0.99320, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.11-0.9932.hdf5\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0212 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99320\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0215 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99320 to 0.99360, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.13-0.9936.hdf5\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0216 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.99360 to 0.99380, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.14-0.9938.hdf5\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 23s 378us/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.0199 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99380\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.99380 to 0.99390, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.16-0.9939.hdf5\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0233 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99390\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 22s 372us/step - loss: 0.0163 - acc: 0.9942 - val_loss: 0.0213 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99390\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0176 - acc: 0.9939 - val_loss: 0.0202 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99390\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0218 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99390\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 23s 375us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0235 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99390\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.0236 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99390\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0210 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99390\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 23s 375us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0190 - val_acc: 0.9947\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.99390 to 0.99470, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.4.24-0.9947.hdf5\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 23s 378us/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0237 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99470\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0130 - acc: 0.9954 - val_loss: 0.0252 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99470\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0231 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99470\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 23s 378us/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0217 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99470\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 23s 375us/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0226 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99470\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 22s 375us/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0217 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ed7fa97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1TsFDth8uD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=build_third_model()\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "new_lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAsTAdQA0oNU",
        "colab_type": "text"
      },
      "source": [
        "### 2. Best validation accuracy was 99.43 at epoch 18. Next best was 99.4% at epoch 11. \n",
        "This is the best one since even though the accuracy is lower than earlier one, has happened at an earlier epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFgt7X4H846x",
        "colab_type": "code",
        "outputId": "92fa6140-5e46-4b68-de15-80f350845630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file = dir + \"Assign4.5.{epoch:02d}-{val_acc:.4f}.hdf5\" \n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test), callbacks=[checkpoint, new_lr])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.2628 - acc: 0.9160 - val_loss: 0.0574 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98110, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.01-0.9811.hdf5\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0728 - acc: 0.9778 - val_loss: 0.0483 - val_acc: 0.9847\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98110 to 0.98470, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.02-0.9847.hdf5\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0560 - acc: 0.9824 - val_loss: 0.0394 - val_acc: 0.9878\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98470 to 0.98780, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.03-0.9878.hdf5\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0477 - acc: 0.9851 - val_loss: 0.0292 - val_acc: 0.9902\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98780 to 0.99020, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.04-0.9902.hdf5\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0411 - acc: 0.9869 - val_loss: 0.0423 - val_acc: 0.9878\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.99020\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0265 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.99020 to 0.99190, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.06-0.9919.hdf5\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0345 - acc: 0.9890 - val_loss: 0.0279 - val_acc: 0.9904\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99190\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.0317 - acc: 0.9900 - val_loss: 0.0241 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99190 to 0.99260, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.08-0.9926.hdf5\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0307 - acc: 0.9899 - val_loss: 0.0237 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99260 to 0.99280, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.09-0.9928.hdf5\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0240 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99280\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0274 - acc: 0.9911 - val_loss: 0.0211 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.99280 to 0.99400, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.11-0.9940.hdf5\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.0224 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99400\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0232 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99400\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0242 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99400\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0218 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99400\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9934\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99400\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0245 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99400\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.0208 - acc: 0.9933 - val_loss: 0.0233 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.99400 to 0.99430, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Weights/Assign4.5.18-0.9943.hdf5\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0205 - acc: 0.9930 - val_loss: 0.0228 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99430\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.0200 - acc: 0.9933 - val_loss: 0.0241 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb515bffac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eFIsqi_7x22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8843a988-5346-4e21-8816-143e64baf9bd"
      },
      "source": [
        "model.load_weights(dir + \"Assign4.5.18-0.9943.hdf5\")\n",
        "print(\"Loaded model from disk \")\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk \n",
            "[0.023296371747613013, 0.9943]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}